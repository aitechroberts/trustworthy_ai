{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ld1cjurYc3fM","scrolled":true,"executionInfo":{"status":"ok","timestamp":1756444434827,"user_tz":240,"elapsed":41978,"user":{"displayName":"Yaru Niu","userId":"16083468250752391130"}},"outputId":"9400a104-eb02-412b-cddd-df94089f0444"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scratchai-nightly\n","  Downloading scratchai_nightly-0.0.1a3-py3-none-any.whl.metadata (4.7 kB)\n","Downloading scratchai_nightly-0.0.1a3-py3-none-any.whl (87 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scratchai-nightly\n","Successfully installed scratchai-nightly-0.0.1a3\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.1\u001b[0m\u001b[31m\n","\u001b[0mCollecting flashtorch\n","  Downloading flashtorch-0.1.3.tar.gz (28 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from flashtorch) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from flashtorch) (2.0.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from flashtorch) (11.3.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flashtorch) (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from flashtorch) (0.23.0+cu126)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from flashtorch) (6.5.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->flashtorch) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->flashtorch) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->flashtorch) (4.59.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->flashtorch) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->flashtorch) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->flashtorch) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->flashtorch) (2.9.0.post0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->flashtorch) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->flashtorch) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->flashtorch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flashtorch) (3.0.2)\n","Building wheels for collected packages: flashtorch\n","  Building wheel for flashtorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flashtorch: filename=flashtorch-0.1.3-py3-none-any.whl size=26228 sha256=3b82695a616787659c4df0d32dfa9050b8065c19d7e7b05aa335d79de5f34d1b\n","  Stored in directory: /root/.cache/pip/wheels/c0/cb/5a/9c2b300f5b071f152ae77000d76a7d8dc58fdba7b3fef05afe\n","Successfully built flashtorch\n","Installing collected packages: flashtorch\n","Successfully installed flashtorch-0.1.3\n","Collecting mapextrackt\n","  Downloading mapextrackt-0.4.8.6-py3-none-any.whl.metadata (3.7 kB)\n","Downloading mapextrackt-0.4.8.6-py3-none-any.whl (13 kB)\n","Installing collected packages: mapextrackt\n","Successfully installed mapextrackt-0.4.8.6\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n","Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n"]}],"source":["!pip install scratchai-nightly  # for adversarial attack\n","!pip install torchvision==0.9.1 # deep learning models\n","!pip install flashtorch         # visualization based on activation maximization\n","!pip install mapextrackt        # visualization of neural network saliency map\n","!pip install tqdm\n","!pip install requests\n","!pip install opencv-python\n","!pip install scipy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KjduJjJ0TKHi","scrolled":true},"outputs":[],"source":["# download and store locally a stop sign image\n","stop_sign_url = 'https://static01.nyt.com/images/2011/12/11/magazine/11wmt1/mag-11WMT-t_CA0-jumbo.jpg'\n","!mkdir input_images\n","!wget https://static01.nyt.com/images/2011/12/11/magazine/11wmt1/mag-11WMT-t_CA0-jumbo.jpg -O input_images/stop.jpg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nR0D616vcb3Q","scrolled":true},"outputs":[],"source":["# suppress error\n","import logging as logging\n","import sys as sys\n","logging.disable(sys.maxsize)\n","\n","# import the library\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torchvision import models\n","from scratchai import *\n","\n","from flashtorch.activmax import GradientAscent\n","from MapExtrackt import FeatureExtractor\n","from torch.distributions import Normal\n","\n","\n","# set parameters\n","stop_sign_path = 'input_images/stop.jpg' #stop sign image path\n","true_class = 919 # imagenet id for street sign\n","\n","\n","# function handle to get prediction more easily\n","def get_prediction(image, model):\n","    #assumes img and net are datasets and models trained using imagenet dataset\n","    confidences = model(image.unsqueeze(0))\n","    class_idx = torch.argmax(confidences, dim=1).item()\n","    class_label = datasets.labels.imagenet_labels[class_idx]\n","    return class_label, confidences[0, class_idx].item(), class_idx"]},{"cell_type":"markdown","metadata":{"id":"UONF5q8GnL-9"},"source":["**1a: Making prediction**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPBfnb9LnV5w","scrolled":true},"outputs":[],"source":["# load and preprocess the stop sign image\n","img = imgutils.load_img(stop_sign_path)\n","img = imgutils.get_trf('rz256_cc224_tt_normimgnet')(img) #normalize and reshape the input image\n","\n","# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","net = ...  # load resnet\n","\n","# use the provided get_prediction function to predict the class of the stop sign image\n","..."]},{"cell_type":"markdown","metadata":{"id":"2cgmdL6ol3Vu"},"source":["**1b: Random perturbation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-bdQKHM11b8","scrolled":true},"outputs":[],"source":["# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","epsilon = ... # set the epsilon\n","\n","torch.manual_seed(0) # set the random seed when you use functions that uses sampling\n","\n","noisy_img = ... # perform uniform random attack here [see the example in the Sec. 3.2.4 of the problem set]\n","\n","... # output prediction, conf, and label_id using get_prediction function\n","\n","imgutils.imshow([img, noisy_img-img, noisy_img], normd=True) #output the original image, the perturbation image, the perturbed image"]},{"cell_type":"markdown","metadata":{"id":"C3la24BqoIoq"},"source":["**1c: FGM Attack**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ir0HrrBmoH-f","scrolled":true},"outputs":[],"source":["# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","images, true_labels, predicted_labels = ... # perform FGM attacks and return all the outputs\n","\n","imgutils.imshow(images) # show all the images [original, perturbation, and adversarial]\n","\n","true_labels, predicted_labels # show true and predicted labels"]},{"cell_type":"markdown","metadata":{"id":"WmHUxpEcp6_b"},"source":["**1d: PGD Attack**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kKgBr9V_p-bH","scrolled":true},"outputs":[],"source":["# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","target_class = 829 # imagenet id for street car\n","\n","images, true_labels, predicted_labels = ... # perform PGD attacks and return all the outputs\n","\n","imgutils.imshow(images) # show all the images [original, perturbation, and adversarial]\n","\n","true_labels, predicted_labels #show true and predicted labels"]},{"cell_type":"markdown","metadata":{"id":"qJcAfvWPq_nn"},"source":["**2a: AlexNet layer 0 visualization**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GEB9Pb2rN1-","scrolled":true},"outputs":[],"source":["# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","model = ...  #load pretrained alexnet\n","\n","print(model) #show the alexnet structure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIldOtt5Vv9M","scrolled":true},"outputs":[],"source":["# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","#load GradientAscent on GPU\n","g_ascent = GradientAscent(model.features)\n","g_ascent.use_gpu = True\n","\n","layer_idx = ... # set the layer index\n","\n","filters = ... # set the filter numbers\n","\n","layer = model.features[layer_idx] # select the 1st conv layer\n","\n","... # call g_ascent.visualize() with the correct arguments to output the visualization\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LN8N5LF4shIH"},"source":["**2b: AlexNet layer 10 visualization**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"060YWSuxskYY","scrolled":true},"outputs":[],"source":["# MODIFY THE CODE FOR 2a TO VISUALIZE LAYER 10, FILTERS [5, 10, 15, 20] OF ALEXNET\n"]},{"cell_type":"markdown","metadata":{"id":"AJju0cues6UM"},"source":["**2c: AlexNet saliency map with the stop sign image**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEum1jNNtFJ6","scrolled":true},"outputs":[],"source":["# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","# load FeatureExtractor\n","from MapExtrackt import FeatureExtractor\n","\n","layer_idx = ... #define the layer index\n","\n","fe = FeatureExtractor(model)\n","\n","fe.set_image(stop_sign_path) # stop_sign_path is the path to the stop sign image\n","\n","fe.display_from_map(layer_no=layer_idx)"]},{"cell_type":"markdown","metadata":{"id":"-VxqVp4ceSCZ"},"source":["**3: Example of plot with a confidence interval**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LugmhXM6eiIN","scrolled":true},"outputs":[],"source":["#THIS IS JUST AN EXAMPLE TO PLOT CONFIDENCE INTERVAL AS SHADED AREA\n","\n","n = 500 # number of samples\n","k = 10  # number of replications\n","sigma = 0.2\n","\n","torch.manual_seed(0) # set the random seed\n","deltas = torch.FloatTensor(sigma*torch.randn(n, k)) # gaussian samples ~ N(0, sigma*I)\n","\n","# compute mean and standard deviation\n","mean_ = deltas.mean(dim=0)\n","std_ = deltas.std(dim=0)\n","\n","# generate the plot\n","x = np.arange(k) # populate x axis\n","plt.plot(x, mean_, label=\"Estimated mean of $\\delta$\")\n","plt.fill_between(x, mean_ - std_, mean_ + std_, alpha=0.5, label=\"Confidence Interval\") # 1-sigma confidence interval\n","plt.legend()\n","plt.ylim([None, 0.4])\n","plt.title('Example plot')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"O3AMV6r1pKpG"},"source":["**Density computation example with log_prob**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PIyF9mbpnVNx","scrolled":true},"outputs":[],"source":["# THIS IS AN EXAMPLE TO USE log_prob METHOD FOR EASIER DENSITY COMPUTATION\n","\n","# Suppose you want to compute the density of Normal distribution\n","\n","# create Normal distribution object\n","p = Normal(torch.tensor([0.0]), torch.tensor([sigma]))       # N(0, sigma**2)\n","p_tilde = Normal(torch.tensor([0.2]), torch.tensor([sigma])) # N(1, sigma**2)\n","\n","# use log_prob method\n","log_density_orig = p.log_prob(deltas) # log_prob method gives you log densities\n","log_density_tilde = p_tilde.log_prob(deltas)\n","\n","# verify this by plotting the density, i.e. the exp of the log_density\n","plt.scatter(deltas, torch.exp(log_lkl_orig), label=\"p\")\n","plt.scatter(deltas, torch.exp(log_lkl_tilde), label=\"p_tilde\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"3t_QzPeFt0kH"},"source":["**3a: MC estimator for prob. robustness of ResNet-18**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zC0Qmm7audHo","scrolled":true},"outputs":[],"source":["# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","net = ... # load resnet\n","\n","sigma_squared = # parameter sigma\n","\n","# evaluate the model k times, each time use n samples\n","k = ... # number of replications\n","n = ... # number of samples in each replication\n","\n","# collect the samples\n","torch.manual_seed(0) # set the random seed\n","deltas = torch.FloatTensor(sigma_squared*torch.randn(*img.shape, n, k)) # gaussian samples ~ N(0, sigma**2*I)\n","\n","resnet_test=np.zeros([n, k])\n","\n","for i in range(k):\n","    for j in range(n):\n","        noisy_img = img + deltas[:, :, :, j, i]\n","        _, _, y_i = get_prediction(noisy_img, net)\n","        resnet_test[j, i] = y_i != true_class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dzEQwTbjpRC","scrolled":true},"outputs":[],"source":["# compute the mean and standard deviation of your estimator\n","mu_hat_n_samples = resnet_test.mean(axis=0)\n","\n","mean_ = mu_hat_n_samples.mean()\n","std_ = mu_hat_n_samples.std()\n","\n","mean_, std_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DkePaA-Mb2fz","scrolled":true},"outputs":[],"source":["# REPEAT THE ABOVE EXAMPLE FOR n = [50, 100, 150, ..., 500]\n","...\n","\n","# PLOT THE MEAN AND THE CONFIDENCE INTERVAL OF THE k VALUES OF mu_hat_n VS n\n","..."]},{"cell_type":"markdown","metadata":{"id":"GhNIWENGu_d0"},"source":["**3b: MC relative error**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQ-bwFPNvIJd","scrolled":true},"outputs":[],"source":["# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","mu = 0.03 #true mu value\n","\n","relative_error = ... # compute the relative error\n","\n","# PLOT THE RELATIVE ERROR VS n\n","..."]},{"cell_type":"markdown","metadata":{"id":"_RnuMV_avIiO"},"source":["**3c: Misclassification rate w.r.t. samples close to an adversarial example**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUgEf91Yvf9w","scrolled":true},"outputs":[],"source":["# REPLACE THE THREE DOTS WITH YOUR OWN CODE\n","\n","# repeat the FGM attack from problem 1c\n","xtilde = ...\n","\n","# perform mean shift, closer to the adversarial example\n","scale = 1/3\n","mean_shift = scale*xtilde\n","\n","# generate Gaussian samples centered at the mean_shift\n","torch.manual_seed(0) # set the random seed\n","\n","deltas = ...\n","\n","# compute misclassification rate using this new deltas, similar to 3a above\n","..."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}